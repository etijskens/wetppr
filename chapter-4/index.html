<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../img/favicon.ico">
        <title>chapter 4 - Case studies - Parallel Programming</title>
        <link href="../css/bootstrap.min.css" rel="stylesheet">
        <link href="../css/font-awesome.min.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/color-brewer.min.css">
        <link href="../assets/_mkdocstrings.css" rel="stylesheet">

        <script src="../js/jquery-1.10.2.min.js" defer></script>
        <script src="../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="..">Parallel Programming</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href=".." class="nav-link">Home</a>
                            </li>
                            <li class="navitem">
                                <a href="../glossary/" class="nav-link">Glossary</a>
                            </li>
                            <li class="navitem">
                                <a href="../links/" class="nav-link">Useful links</a>
                            </li>
                            <li class="navitem">
                                <a href="../overview/" class="nav-link">Overview</a>
                            </li>
                            <li class="navitem">
                                <a href="../course-text/" class="nav-link">Course text</a>
                            </li>
                            <li class="navitem">
                                <a href="../exercises/" class="nav-link">Exercises</a>
                            </li>
                            <li class="navitem">
                                <a href="../evaluation/" class="nav-link">Evaluation of this course</a>
                            </li>
                            <li class="navitem">
                                <a href="../vsc-infrastructure/" class="nav-link">VSC infrastructure</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#chapter-4-case-studies" class="nav-link">chapter 4 - Case studies</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#monte-carlo-ground-state-energy-calculation-of-a-small-atom-cluster" class="nav-link">Monte Carlo ground state energy calculation of a small atom cluster</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#study-of-data-access-patterns-in-a-large-lennard-jones-systems" class="nav-link">Study of data access patterns in a large Lennard-Jones systems</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<div><h1 id="chapter-4-case-studies">chapter 4 - Case studies</h1>
<h2 id="monte-carlo-ground-state-energy-calculation-of-a-small-atom-cluster">Monte Carlo ground state energy calculation of a small atom cluster</h2>
<h3 id="introduction">Introduction</h3>
<p>The code for this benchmark was Kindly provided by Jesus Eduardo Galvan Moya, former PhD student of the Physics 
Department, Condensed Matter Theory.</p>
<p>It is a small molecular dynamics code which happens to serve many didactical purposes. It is simple code, not too big.
Full of issues you should learn to pay attention to ;-)</p>
<p>The goal of the program is to calculate the ground state energy of a small atomistic system of 10-150 atoms. The 
system is at 0K, so there are no velocities, and the total energy of the system consist of the interaction energy 
only. Interactions are described by a pair-wise interaction potential, without cutoff radius (brute force). 
A Monte Carlo approach is used to find the configuration with the lowest energy, 1000 separate runs with different 
initial configuration are run. Each run comprises 200 000 random atom moves. Finally, the run with the lowest energy is kept and subjected to Quasi-Newton iteration in order to find a 
local energy minimum. </p>
<h3 id="implementation">Implementation</h3>
<p>Here is how this algorithm goes (C++ pseudo code):   </p>
<pre><code class="language-C++">n_atoms = 50; // (for example)
std::vector&lt;double&gt; x, y, z, xmin, ymin, zmin;
double Emin = std::numeric_limits&lt;double&gt;::max();
for(int ic=0; ic&lt;1000; ++ic)
{// loop over initial configurations
 // generate initial configuration
    initialize(x,y,z);
    for(int ip=0; ip&lt;200000; ++ip) 
    {// loop over random perturbations
     // perturb the current configuration    
        x += small_perturbation();
        y += small_perturbation();
        z += small_perturbation();
        E = 0;
     // double loop over all interactions
        for(int i=0; i&lt;n_atoms; ++i)
            for(int j=0; j&lt;i; ++j) {
                double rij = std::sqrt((x[j]-x[j])^2 + (y[j]-y[j])^2 + (z[j]-z[j])^2);
                E += V(rij);
            }
        }
    }
    if( E &lt; Emin )
    {// remember the current (perturbed) configuration
        xmin = x;
        ymin = y;
        zmin = z;
        Emin = E
    }
} 
// Perform a Newton-Raphsom iteration on E(x,y,z) with x0 = xmin, y0 = ymin, z = zmin.   
...
</code></pre>
<p>The memory footprint of this problem is (<code>n_atoms</code> x 3) <code>doubles</code> x 8 bytes/<code>double</code>. For <code>n_atoms = 150</code>, that is 
3600 bytes, which is far less than the size of L1 cache (32KB). Hence, the problem fits easily in the L1 cache. As 
soonas the entire problem is loaded in the cache, the code will run without needing to wait for data. Furthermore, the 
interaction potential </p>
<p>
<script type="math/tex; mode=display"> V(r) = A \frac{exp{({\alpha}r)}}{r^n} - B \frac{exp{(-\beta(r-c_{att}))}} {(r-c_{att})^{n_{att}} + d_{att}} 
- \frac{C}{r}</script>
</p>
<p>is rather compute intensive, as it uses several expensive operations: two exponentials and two divisions, plus the 
square root for the distance which here cannot be avoided:</p>
<p>
<script type="math/tex; mode=display"> r = r_{ij}(r_i,r_j) = \sqrt{(x_j-x_i)^2 + (y_j-y_i)^2 + (z_j-z_i)^2 } </script>
</p>
<p>Consequently, the code is certainly compute bound.</p>
<h3 id="optimisation">Optimisation</h3>
<p>Most of the work is carried out in the inner double loop over the interactions. Let's see if we can optimise this. </p>
<p>Initially, both expressions for the interatomic distance <script type="math/tex">r_{ij}(r_i,r_j)</script> and the interaction potential <script type="math/tex">V(r)</script>
were implemented as functions called in the double loop. The first timing for the double loop with 50 atoms is 144 
<script type="math/tex">\mu</script>s. By checking the vectorisation report of the compiler, we learned that the two function calls prohibited 
vectorisation. After inlining the functions,  the timing was reduced to 93 <script type="math/tex">\mu</script>s.<br>
The inner loop contains a lot of short loops. This is bad for pipelining and vectorisation (many loops end with 
incompletely filled vector registers.) If we split the loop in a double loop for calculating the interatomic 
distances and storing them in a long array, and a long loop over that array to compute the interactions, the 
situation might improve. </p>
<pre><code class="language-C++">        E = 0;
        int n_interactions = n_atoms*(n_atoms-1)/2;
        std::vector&lt;double&gt; rij(n_interactions); 
         // (in C++ std::vector is actually a contiguous array)
     // double loop over all interactions
        for(int i=0; i&lt;n_atoms; ++i)
            for(int j=0; j&lt;i; ++j) 
                rij = std::sqrt((x[j] - x[j])^2 + (y[j] - y[j])^2 + (z[j] - z[j])^2);
        }
        for(int ij=0; ij&lt;n_interactions; ++ij)
            E += V(rij[ij]);
</code></pre>
<p>This reduces the time from 93 to 86 <script type="math/tex">\mu</script>s. Not much, but since we must runs this loop 1 000 x 200 000 times it 
nevertheless represents a substantial gain. </p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>We implemented this both in C++ and Fortran. The results were almost identical. You sometimes hear that C++ is 
an inefficient programming language and that the opposite holds for Fortran. This is not true. Both C++ and 
Fortran compilers are capable to build optimally performant progams for the CPU at hand. We'll come to this 
subject <a href="???">later</a>. </p>
</div>
<p>At this point, we seem to be done optimising the inner loops. Maybe there is something we can do to the 
surrounding loops? The perturbation loop adds a small perturbation to every coordinate of every atom in the list to 
see if the perturbation results in a lower energy. The perturbation involves <script type="math/tex">3n_{atoms}</script> random numbers and 
generation random numbers is also rather expensive. We might wonder if it is really necessary to perturb all atoms. 
What if we perturbed only one atom? That reduces the number of random number generations by a factor <script type="math/tex">n_{atoms}</script>. In 
addition, most of the interactions remain the same, only the <script type="math/tex">n_{atoms}-1</script> interactions with the perturbed atom 
change. Hence our program now has a complexity <script type="math/tex">O(N)</script>. In the original formulation the number of interaction to be 
computed was <script type="math/tex">n_{atoms}(n_{atoms}-1)/2 = O(N^2)</script>. As the program is compute bound changing the computational 
complexity  from <script type="math/tex">O(N^2)</script> to <script type="math/tex">O(N)</script> will have a big impact. This optimisation falls under the 
<a class="autorefs autorefs-internal" href="../chapter-3/#common-sense-optimisations">common sense optimisations</a>. </p>
<p>It is important to realize that this optimisation changes the nature of the algorithm. It remains to be seen whether 
200 000 configurations is still sufficient to find the minimum. We might need more, or maybe less. This up to 
the researcher to investigate. </p>
<p>Let's see how we can implement this modification and how that effects the performance. We start with depicting the 
relation between $r_{ij}) as a (lower triangular) matrix and as the linear <code>rij</code> array in the split loop above. </p>
<p><img alt="rij" src="../public/rij.png"></p>
<p>The linear array stores the rows of the lower triangular matrix: <script type="math/tex">[r_{10}</script>, <script type="math/tex">r_{20}</script>, <script type="math/tex">r_{21}</script>, <script type="math/tex">r_{30}</script>, <script type="math/tex">r_{31}</script>, 
<script type="math/tex">r_{32}, r_{40}</script>, <script type="math/tex">r_{41}</script>, <script type="math/tex">r_{42}</script>, <script type="math/tex">r_{43}</script>, ... <script type="math/tex">]</script>. The matrix elements show the value or the 
index into the linear array. Let's do something similar for the interaction energy:</p>
<p><img alt="Eij" src="../public/Eij.png"></p>
<p>We have added a column to compute the row sums and the total sum of the interaction energies <script type="math/tex">E_{ij}</script>. Let's now 
visualize the changes when an atom, say atom 4, is perturbed.</p>
<p><img alt="Eij" src="../public/Eij-perturb-4.png"></p>
<p>The items changing due to perturbing <script type="math/tex">r_4</script> are marked in orange. The row sum for row 4 has to be computed from scratch
and in row 5 and 6 the elements corresponding to column 4 change as well. The next figure shows how the perturbed 
result can be computed from the previous result by first subtracting the previous result and then adding the new 
result. </p>
<p><img alt="Eij" src="../public/Eij-perturb-4-bis.png"></p>
<p>Here is a comparison of the timings:</p>
<table>
<thead>
<tr>
<th>
<script type="math/tex">N</script>
</th>
<th>
<script type="math/tex">O(N^2)</script>
</th>
<th>
<script type="math/tex">O(N)</script>
</th>
<th>speedup</th>
</tr>
</thead>
<tbody>
<tr>
<td>50</td>
<td>86 <script type="math/tex">\mu</script>s</td>
<td>5.7</td>
<td>15.1</td>
</tr>
<tr>
<td>150 (x3)</td>
<td>747 <script type="math/tex">\mu</script>s (x9)</td>
<td>17.3 <script type="math/tex">\mu</script>s (x3)</td>
<td>43.3</td>
</tr>
<tr>
<td>500 (x10)</td>
<td>8616 <script type="math/tex">\mu</script>s (x100)</td>
<td>57.0 <script type="math/tex">\mu</script>s (x10)</td>
<td>115.2</td>
</tr>
</tbody>
</table>
<p>Clearly, the timings for the <script type="math/tex">O(N^2)</script> algorithm increase quadratically, while those for the <script type="math/tex">O(N)</script> algorithm increase 
only linearly and the speedups are substantial. The <script type="math/tex">O(N)</script> algorithm for 500 atoms - a number that our researcher 
considered unattainable because it would take too long to compute - is still faster than the <script type="math/tex">O(N)</script> algorithm.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p><strong><em>Look for algorithms of low computational complexity.</em></strong> However, The best algorithme may also depend on the 
problem as we saw in <a class="autorefs autorefs-internal" href="../chapter-2/#selecting-algorithms-based-on-computational-complexity">Selecting algorithms based on computational complexity</a>.  </p>
</div>
<p>Despite the considerable performance improvement, there are a few disadvantages to it too. The <script type="math/tex">O(N)</script> algorithm has 
more code, is more difficult to understand and thus harder to maintain. Morover, its loops are more complex, making 
it harder for the compiler to optimize. Autovectorisation doesn't work. If it needs further optimization, it is 
certainly no low-hanging fruit.   </p>
<h3 id="parallelization">Parallelization</h3>
<p>If the time of solution for this sofar sequential program is still too large, we might opt for parallelization. The 
interaction loop is now doing relatively little work, and hard to parallelize. On the other hand the perturbation 
loop can be easily distributed over more threads as this loop is 
<a class="autorefs autorefs-internal" href="../chapter-1/#what-is-a-parallel-program">embarrassingly parallel</a>. As long as every thread generates a different series of 
random numbers they can run their share of the perturbation iterations completely independent. This is very easy to 
achieve with OpenMP. In the end every thread would have its own minimum energy configuration, and the overall 
minimum energy configuration is simply found as the minimum of per thread minima. Since every core has its own L1 
cache, the problem for each thread also fits in L1. </p>
<h3 id="project-mcgse">Project mcgse</h3>
<p>The <code>wetppr/mcgse</code> folder repeats this case study for the <a href="https://en.wikipedia.%0Aorg/wiki/Morse_potential">Morse potential</a> (I lost the original code :-( )</p>
<p>
<script type="math/tex; mode=display"> V(r) = D_e(1 - e^{-\alpha(r-r_e)})^2 </script>
</p>
<p>We will assume that all parameters are unity. </p>
<p>
<script type="math/tex; mode=display"> V(r) = (1 - e^{1-r)})^2 </script>
</p>
<p>Here is its graph:</p>
<p><img alt="morse" src="../public/morse.png"></p>
<p>Using our <a href="../chapter-5/">research software devolopment strategy</a>, we start in Python, implement both algorithms and 
test. A good test is the case of a cluster of 4 atoms. Energy minimum then consists of a tetrahedron with unit sides.
Every pair is then at equilibrium distance and <script type="math/tex">E_{min}=0</script>. The vertices of the tetrahedron are on a sphere of 
radius <script type="math/tex">\sqrt{3/8}</script>. Let us randomly distribute 4 points on a sphere of radius <script type="math/tex">\sqrt{3/8}</script> and see how well close 
we get to <script type="math/tex">E_{min}=0</script>. </p>
<pre><code class="language-python">    import numpy as np
    import mcgse # our module for this project: wetppr/mcgse
    sample = mcgse.sample_unit_sphere(4) * np.sqrt(3/8)
    config = (sample[0], sample[1], sample[2]) # initial coordinates of the atoms (x,y,z)
    dist = mcgse.LogNormal(mean=-5, sigma=.4) # distribution to draw the length of the displacements from
    #   the distribution and its parameters were selected using quite some trial and error to obtain 
    #   useful results...
    Emin_ON2, *config_min_ON2 = mcgse.execute_perturbation_loop(config=config, n_iterations=20000, dist=dist, algo='ON2', verbosity=1)
    Emin_ON , *config_min_ON  = mcgse.execute_perturbation_loop(config=config, n_iterations=20000, dist=dist, algo='ON' , verbosity=1)
</code></pre>
<p>Here are the results for 5 runs:</p>
<pre><code class="language-python">ON2 iteration 0: Emin=1.8642580817361518
ON2 iteration 200000: Emin=0.343375960680797, last improvement: iteration = 2044
ON iteration 0: Emin=1.8642580817361518
ON iteration 200000: Emin=0.1318184548419835, last improvement: iteration = 30162

ON2 iteration 0: Emin=1.0114013021541974
ON2 iteration 200000: Emin=0.368488427516059, last improvement: iteration = 32701
ON iteration 0: Emin=1.0114013021541974
ON iteration 200000: Emin=0.058861153165589014, last improvement: iteration = 5168

ON2 iteration 0: Emin=3.69912617914294
ON2 iteration 200000: Emin=0.3819530373342961, last improvement: iteration = 4580
ON iteration 0: Emin=3.69912617914294
ON iteration 200000: Emin=0.3297933435887894, last improvement: iteration = 65216

ON2 iteration 0: Emin=3.299140128625619
ON2 iteration 200000: Emin=0.5323556068840862, last improvement: iteration = 12505
ON iteration 0: Emin=3.299140128625619
ON iteration 200000: Emin=0.5270227273967558, last improvement: iteration = 16929

ON2 iteration 0: Emin=1.2894488159651718
ON2 iteration 200000: Emin=0.40188231571036437, last improvement: iteration = 2621
ON iteration 0: Emin=1.2894488159651718
ON iteration 200000: Emin=0.07936811573814093, last improvement: iteration = 25806
</code></pre>
<p>We can draw some interesting observations from these runs:</p>
<ul>
<li>Neither of the algorithms seem to get close to the minimum,</li>
<li>In terms of closeness to the minimum there no clear winner, although <code>ON</code> got rather close twice,</li>
<li>The higher the initial energy, the worse the solution, which is acceptable, as the average displacement magnitude 
  is fixed.</li>
<li>None of the algorithms seems to converge. In the first and the last run <code>ON2</code> found its best guess at 2044 and 
  2621 iterations. None of the approximately 198_000 later attempts could reduce the energy. This seems to be the 
  case for <code>ON</code> as well, although the numbers are a bit higher. Despite being far from the minimum, improvements 
  seem to involve progressively more work. </li>
</ul>
<p>Especially the last conclusion is rather worrying. Our algorithms don't seem to sample the configuration space very 
efficiently. </p>
<p>Perhaps, rather than displacing the atoms randomly, it might be more efficient to move them in the direction of the 
steepest descent of the energy surface. Since we have an analytical expression, we can compute it. The interaction 
<script type="math/tex">V(r_{ij})</script> exerts a force </p>
<p>
<script type="math/tex; mode=display"> {\mathbf{F}}_k = -\nabla_{\mathbf{r}_k}E </script>
</p>
<p>
<script type="math/tex; mode=display"> = -\nabla_{\mathbf{r}_k} \sum_{i<j}V(r_{ij}) = -\sum_{i<j}
\nabla_{\mathbf{r}_k}V(r_{ij})</script>
</p>
<p>
<script type="math/tex; mode=display">= -\sum_{i<j}
\frac{d}{d_{r_{ij}}}V(r_{ij})\nabla_{\mathbf{r}_k}r_{ij} = -\sum_{i<j} V'(r_{ij})\nabla_{\mathbf{r}_k}r_{ij}</script>
</p>
<p>Here, </p>
<p>
<script type="math/tex; mode=display">\nabla_{\mathbf{r}_k}r_{ij} = 0 \text{  if  } k \ne i,j </script>
</p>
<p>and</p>
<p>
<script type="math/tex; mode=display">\nabla_{\mathbf{r}_k}r_{kj} = -\frac{\mathbf{r}_{kj}}{r_{kj}} = -{\hat{\mathbf{r}}}_{kj}</script>
</p>
<p>
<script type="math/tex; mode=display">\nabla_{\mathbf{r}_k}r_{jk} = \frac{\mathbf{r}_{jk}}{r_{jk}} = {\hat{\mathbf{r}}}_{jk}</script>
</p>
<p>Thus, </p>
<p>Hence:</p>
<p>
<script type="math/tex; mode=display"> \mathbf{F}_k = \sum_{j\ne{k}} V'(r_{kj}){\hat{\mathbf{r}}}_{kj} = -\sum_{j<k} V'(r_{jk}){\hat{\mathbf{r}}}_{jk} 
+ \sum_{k<j} V'(r_{kj}){\hat{\mathbf{r}}}_{kj}</script>
</p>
<p>Finally (setting all parameters to unity),  </p>
<p>
<script type="math/tex; mode=display"> V'(r) = -2(1-e^{1-r})e^{1-r}</script>
</p>
<p>Now that we have the forces on the atoms in the current configuration, we should be able to move the atoms in the 
directon of the force, rather than in a random direction, as before. In fact we have a true minimisation problem now.</p>
<p>to be continued...</p>
<h2 id="study-of-data-access-patterns-in-a-large-lennard-jones-systems">Study of data access patterns in a large Lennard-Jones systems</h2>
<h3 id="introduction_1">Introduction</h3>
<p>In this case study we consider a large system of atoms whose interaction is described by a Lennard-Jones potential. 
By large we mean a system that does not fit in the cache. Consequently, the effect of caches will be noticabel in 
the results. We will consider two different settings. A Monte Carlo setting, as above, in which the interaction 
energy is computed as a sum of pairwise interactions. It is of little physical significance, but is useful to 
demonstrate the effect of the caches on the computations. </p>
<p>The second setting is a true molecular dynamics setting in which the time evolution of a collection of atoms is 
computed by time integration of the interaction forces which are computed as the gradient of the interaction potential.
This gives rise to time dependent accelerations, velocities and positions of the atoms. </p>
<h3 id="monte-carlo-setting">Monte Carlo setting</h3>
<p>The interaction energy is given by:</p>
<p>
<script type="math/tex; mode=display"> E=\sum_{i<j}V(r_{ij}) </script>
</p>
<p>Since our sytem is large, say billions of atoms, computing this sum considering all pairs, is computationally 
unfeasible because it has <script type="math/tex">O(N^2)</script> computational complexity. We will discuss approaches to reduce the computational 
complexity to <script type="math/tex">O(N)</script>. To study the effect of the cache we will compute the partial sum  </p>
<p>
<script type="math/tex; mode=display"> E_i=\sum_{j\ne{i}}V(r_{ij}) </script>
</p>
<p>for <script type="math/tex">i=0</script>, that is </p>
<p>
<script type="math/tex; mode=display"> E_0=\sum_{j=1}^{N}V(r_{0j}) </script>
</p>
<p>Because our system is translationally invariant, we can put atom <script type="math/tex">0</script> at the origin, in which case <script type="math/tex">r_{0j}=r_j</script>. 
Thus, we end up with:</p>
<p>
<script type="math/tex; mode=display"> E_0=\sum_{j=1}^{N}V(r_{j}) </script>
</p>
<p>We will use the best implementation for the Lennard-Jones potential that we discussed in 
<a class="autorefs autorefs-internal" href="../chapter-2/#the-cost-of-floating-point-instructions">The cost of floating point instructions</a>, expressed as a function of <script type="math/tex">r^2</script>,
as to avoid the square root needed to compute <script type="math/tex">r</script>. We consider three different cases:</p>
<ol>
<li>A contiguous loop over arrays <code>x[1:N]</code>, <code>y[1:N]</code>, <code>z[1:N]</code>. This is a structure of arrays (SoA) approach.</li>
<li>A contiguous loop over a single array <code>xyz[1:3N</code>, in which the <script type="math/tex">x</script>, <script type="math/tex">y</script> and <script type="math/tex">z</script> coordinates of the <script type="math/tex">i</script>-th 
   atom come after each other followed by the  <script type="math/tex">x</script>, <script type="math/tex">y</script> and <script type="math/tex">z</script> coordinates of the <script type="math/tex">i+1</script>-th atom. This is a array of 
   structures approach (AoS).</li>
<li>A contiguous loop over arrays <code>x[1:N]</code>, <code>y[1:N]</code>, <code>z[1:N]</code> in which the atoms are picked by random permutation of 
   <script type="math/tex">1..N</script>. So, all atoms are visited, but in a random order. </li>
</ol>
<p>For each case <script type="math/tex"> E_0=\sum_{j=1}^{N}V(r_{j}) </script> is computed for <script type="math/tex">N \in \{2^9,2^10,2^11,...,2^{29}\}</script> repeating the loop 
over <script type="math/tex">j</script>
<script type="math/tex">2^{29}/N</script> times. In this way the amount of interaction potential evaluations is exactly <script type="math/tex">2^{29}</script> 
irrespective of the length of the array, and the timings can be compared. The smallest arrays fit in L1, while the 
longest arrays (<script type="math/tex">2^29\approx0.5\times10^9</script>) do not even fit in L3. Here are the timings:</p>
<p><img alt="0" src="../public/LJ-system-MC-setting-0.png"></p>
<p>It is clearly visible that the behaviour of the random case above is very different from the two contiguous cases. 
For the longest arrays, the performance is a whopping 15x worse on the random loop, yet every case performs exactly 
the same work. There burning question is of course: "what is causing the performance breakdown of the randomized 
loop"? The second question, certainly less burning, but nevertheless important, is: "is the lowest curve (the AoS 
case) the best we can get?". If you are really curious, you might wonder about the small difference between the AoS 
case and the SoA case at larger <script type="math/tex">N</script>. To help your understanding of the problem, here is a different representation 
of the same graph, this time the number of bytes used by the arrays on the x-axis instead of the array size <script type="math/tex">N</script>. 
With this x-axis it is easy to draw the boundaries of the L1, L2 and L3 caches. </p>
<p><img alt="1" src="../public/LJ-system-MC-setting-cache-boundaries.png"></p>
<p>Surprisingly enough, the changes in 
the curves coincide with the cache boundaries. As soon as the problem is too large for a cache, cache misses cause 
pipeline stalls, and the CPU has to wait for the data needed. The latency increases at every cache boundary and the 
slowdown becomes more pronounced each time. This also explains the slight advantage for the AoS case over the SoA 
case for problems not fitting in L3. As x, y, and z follow contiguously in memory in the AoS case, when it needs new 
data from memory, it has to wait for only a single cache line, while the SoA needs three. If you have difficulties 
to grasp, revisit the talk by Scott Meyers <a href="https://www.youtube.com/watch?v=WDIkqP4JbkE"><em>CPU Caches and Why You Care</em></a>.</p>
<p>The second question is a bit harder to answer. Let us analyze the performance of the (Fortran) loop:</p>
<pre><code class="language-fortran">! Contiguous access, SoA: p=[xxx…yyy…zzz…]
do ik=1,k
    do im=1,m                           !  FLOPS
        r2 = (p(im)-x0)**2              !
            +(p(m+im)-y0)**2            !
            +(p(2*m+im)-z0)**2          ! 3-, 2+, 3*
!       r = lj_pot2(r)                  !
        r2i = 1.0d0/r2                  ! 1/
        rr6i = r2i*r2i*r2i;             ! 2*
        V0j = 4.0d0*rr6*(rr6-1.0d0);    ! 2*, 1-
    enddo                               !------------
enddo                                   ! 14 flops
</code></pre>
<p>The loop has 14 floating point operations. It is executed <script type="math/tex">2^29</script> times in 1.2s. That makes <script type="math/tex">6.26\times 10^9</script> flops/s.
The peak performance of the machine is 1 core x 1 instruction per cycle x 4 SIMD registers per instruction x 2.8 GHz = 
11.2 Gcycles/s = 11.2 Gflops/s. Consequently, we are running at 56% of the peak performance. So it looks as if we 
could still do better.  </p>
<p><img alt="2" src="../public/LJ-system-MC-setting-peak-performance.png"></p>
<p>Let us analyze the data traffic of the same loop:</p>
<pre><code class="language-fortran">! Contiguous access, SoA: p=[xxx…yyy…zzz…]
do ik=1,k
    do im=1,m                           ! FLOPS         ! DATA
        r2 = (p(im)-x0)**2              !               !
            +(p(m+im)-y0)**2            !               !
            +(p(2*m+im)-z0)**2          ! 3-, 2+, 3*    ! 3DP
!       r = lj_pot2(r)                  !               !
        r2i = 1.0d0/r2                  ! 1/            !
        rr6i = r2i*r2i*r2i;             ! 2*            !
        V0j = 4.0d0*rr6*(rr6-1.0d0);    ! 2*, 1-        !
    enddo                               !---------------!-----
enddo                                   ! 14 flops      ! 24B
</code></pre>
<p>The loop reads 24 bytes x <script type="math/tex">2^29</script> iterations in 1.2 s. That makes 10.7 GB/s. The bandwidth of the machine is 109 
GB/s for 10 cores, that is 10.9 GB for 1 core. Our loop runs at the maximum bandwidth. It is <strong>bandwith saturated</strong>. 
This is a machine limit. It can simply not feed the CPU with data faster than this. It is instructive to draw a 
roofline model for this. </p>
<p><img alt="3" src="../public/LJ-system-MC-setting-roofline.png"></p>
<p>The above loop, that is the contiguous cases, plot on the bandwidth part of the roofline indicating that the machine 
limit (bandwidth) is reached, the random case sits close to the bottom far away from all machine limits. The 
conclusion is that the loop as it is runs at its maximum speed, being bandwidth limited. However, 44% of the time 
the CPU is not doing useful work, because it is waiting for data. That means that if we replaced the Lennard-Jones 
potential with another one that is about twice as compute intensive, and for that reason more accurate, we would still 
finish the computation in 1.2s and have a more accurate solution, because we are using the cycles that the CPU was 
waiting for data to do the extra computations. </p>
<h3 id="molecular-dynamics-setting">Molecular Dynamics setting</h3>
<p>We consider the same system, a large collection of atoms interacting through a Lennard-Jones potential. In a 
Molecular Dynamics setting the time evolution of th system is computed by time integration of the classical equation 
of motion:</p>
<p>
<script type="math/tex; mode=display"> \dot{\mathbf{r}} = \mathbf{v} </script>
</p>
<p>
<script type="math/tex; mode=display"> \dot{\mathbf{v}} = \mathbf{a} </script>
</p>
<p>
<script type="math/tex; mode=display"> \mathbf{a} = \mathbf{F} </script>
</p>
<p>The forces are computed as the gradient of the interaction energy:</p>
<p>
<script type="math/tex; mode=display"> \mathbf{F}_i = \nabla_{\mathbf{r}_i}{E} = \nabla_{\mathbf{r}_i} \sum_{j\ne{i}}^{N}V(r_{ij}) </script>
</p>
<p>We assume a system size of <script type="math/tex">N=10^9</script> atoms. The number of terms in the sum above is then <script type="math/tex">10^9(10^9-1)/2\approx{10^
{18}}</script>. That will keep us busy, won't it... However, when you start evaluating all these contributions, you very 
soon realize that most of them are really small, so small that they don't actually contribute to the result. They 
are <strong>short-ranged</strong>. Mathematically, a force is short-ranged if it decays faster than <script type="math/tex">r^{-2}</script>. This is because the 
area of a sphere with radius <script type="math/tex">r</script> is <script type="math/tex">4\pi r^2</script> and hence the number of particles at distance grows as <script type="math/tex">r^2</script>. 
Consequently, in order for the force exerted by those particle to be negligible it has to decay faster than <script type="math/tex">r^{-2}</script>.</p>
<p>The derivative of the Lennard-Jones potential is:</p>
<p>
<script type="math/tex; mode=display"> V'(r) = ({-6}/{r}) r^{-6}(2r^{-6}-1) </script>
</p>
<p>Hence,</p>
<p>
<script type="math/tex; mode=display"> \mathbf{F}_i = \sum_{j\ne{i}}^{N}\nabla_{\mathbf{r}_i}V(r_{ij}) = \sum_{j\ne{i}}^{N}V'(r_{ij})\nabla_{\mathbf{r}
_i}r_{ij} = \sum_{j\ne{i}}^{N}V'(r_{ij}) \hat{\mathbf{r}}_{ij} </script>
</p>
<p>
<script type="math/tex; mode=display"> = \sum_{j\ne{i}}^{N} ({-6}/{r_{ij}}) r_{ij}^{-6}(2r_{ij}^{-6}-1) \frac{\mathbf{r}_{ij}}{r_{ij}} = \sum_{j\ne{i}}^
{N} -6 r_{ij}^{-8}(2r_{ij}^{-6}-1) \mathbf{r}_{ij} </script>
</p>
<p>Note that the force factor <script type="math/tex">f</script>, that is the factor in front of <script type="math/tex">\mathbf{r}_ij</script>, can also be expressed in terms of 
<script type="math/tex">s=r^2=\delta{x}^2+\delta{y}^2+\delta{x}^2</script>:</p>
<p>
<script type="math/tex; mode=display"> f(s) = -6 s^{-4}(2s^{-3}-1) </script>
</p>
<p>
<script type="math/tex; mode=display"> \mathbf{F}_i = \sum_{j\ne{i}}^{N} f(s_{ij}) \mathbf{r}_{ij} </script>
</p>
<p>So, we can avoid the square root in computing <script type="math/tex">r_ij</script>. Clearly, we can compute the interaction energy and the 
interaction force in one go with little extra effort:</p>
<p>
<script type="math/tex; mode=display"> V(s) = s^{-3}(s^{-3}-1) </script>
</p>
<p>
<script type="math/tex; mode=display"> E = \sum_{i<j} V(s_{ij}) </script>
</p>
<p>The fact that the interaction force is short-ranged, allows us to neglect the interaction forces beyond a cutoff 
distance <script type="math/tex">r_c</script>, thus offering a possibility to avoid the cost of an <script type="math/tex">O(N^2)</script> algorithm. </p>
<h4 id="implementing-cutoff">Implementing cutoff</h4>
<p>As a first step we we can avoid the computation of the interaction energy and the interaction force if <script type="math/tex">r_{ij}>r_c</script>, 
or <script type="math/tex">s_{ij}>s_c</script>:</p>
<pre><code class="language-python"># (python psseudo-code)
for i in range(N):
    for j in range(i):
        x_ij = x[j]-x[i]
        y_ij = y[j]-y[i]
        z_ij = z[j]-z[i]
        s_ij = x_ij*x_ij + y_ij*y_ij + z_ij*z_ij
        if s_ij &lt;= s_c:
            t = 1/s_ij
            t3 = t*t*t
            E += t3*(t3-1)
            f = -6*t*t3*(2*t3-1)
            Fx[i] += f*x_ij
            Fy[i] += f*y_ij
            Fz[i] += f*z_ij
            Fx[j] -= f*x_ij
            Fy[j] -= f*y_ij
            Fz[j] -= f*z_ij
</code></pre>
<p>Although this loop only computes the interactions wheen <script type="math/tex">s_{ij}\le{s_c}</script>, it still visits every pair to compute 
<script type="math/tex">s_{ij}</script>. The corresponding amount of work is still <script type="math/tex">O(N^2)</script>. Some improvement is possible by using Verlet lists.
The <strong>Verlet list</strong> of an atom <script type="math/tex">i</script> is the set of atoms <script type="math/tex">j</script> for which <script type="math/tex">r_{ij}<r_v</script>, where <script type="math/tex">r_v</script> is typically a bit 
larger than <script type="math/tex">r_c</script>. The loop is now witten as:</p>
<pre><code class="language-python"># (python psseudo-code)
for i in range(N):
    for j in verlet_list(i):
        # as above
</code></pre>
<p>The loop over <script type="math/tex">j</script> is now much shorter, its length is bounded, typically in the range <script type="math/tex">10..100</script>. Hence, the double 
loop is effectively <script type="math/tex">O(N)</script>. The construction of the Verlet list, however, is still <script type="math/tex">O(N^2)</script>, but the cost of it is 
amortised over a number of timesteps. Because atoms move only a little bit over a time step and <script type="math/tex">r_v>r_c</script>, the 
Verlet list can indeed be reused a number of timesteps, before it needs to be updated. </p>
<p>Algorithms for constructing the Verlet list with <script type="math/tex">O(N)</script> complexity do exist. Here's a 2-D version of <strong>cell-based 
Verlet list construction</strong>. It can be easily extended to 3-D, but that is harder to visualise. In the left figure 
below, atom <script type="math/tex">i</script> (the orange dot) is surrounded by a blue circle of radius <script type="math/tex">r_v</script>. Atoms inside the blue circle are in 
the Verlet list of atom <script type="math/tex">i</script>. We now overlay the domain with a square grid, of grid size <script type="math/tex">r_v</script> (middle figure). Atom 
pairs in  the same cell or in nearest neighbour cells are Verlet list candidates, but not pairs in second nearest 
neighbours or further. To construct the Verlet list of atom <script type="math/tex">i</script>, we only have to test atoms in the same cell, or in 
its 8 nearest neighbours, all coloured light-blue. By iterating over all cells and over the atoms it contains, the 
Verlet lists of all atoms can be constructed with <script type="math/tex">O(N)</script> complexity. In fact, by looking for pairs in all 
rearest neighbours, all candidate pairs are visited twice (<script type="math/tex">ij</script> and <script type="math/tex">ji</script>). Hence, only half of the nearest 
neighbours needs to be visited (right figure). </p>
<p><img alt="cell-based-verlet-list" src="../public/cell-based-verlet-list-construction-0-2.png"></p>
<p>The algorithm requires that the grid implements: </p>
<ul>
<li>a cell list: a list of all the atoms that are in the cell, in order to iterate over all atoms in a cell. The cell 
  lists can be constructed with <script type="math/tex">O(N)</script> complexity, and </li>
<li>a method to find the neighbour cells of a cell. </li>
</ul>
<p>This is a good example for demonstrating the effectiveness of our 
<a class="autorefs autorefs-internal" href="../chapter-5/#a-strategy-for-the-development-research-software">strategy for research software development</a>. Here are the steps 
you should take</p>
<ol>
<li>Start out in Python.</li>
<li>Take a small system, <em>e.g.</em> <script type="math/tex">N=5</script>, use Numpy arrays for the positions, velocities, ...</li>
<li>Implement brute force computation of interactions and interaction forces (<script type="math/tex">O(N^2)</script>).</li>
<li>Implement brute force computation of interactions and interaction forces with cutoff (<script type="math/tex">O(N^2)</script>). </li>
<li>Implement brute force construction of Verlet lists (<script type="math/tex">O(N^2)</script>). (You might need a larger system for testing this). </li>
<li>Implement Verlet list computation of interactions and interaction forces (<script type="math/tex">O(N)</script>).</li>
<li>Implement cell-based Verlet list construction (<script type="math/tex">O(N)</script>). (You might need a larger system for testing this).</li>
<li>
<p>Optimise, try using Numba, or by taking the compute intensive parts to C++. </p>
</li>
<li>
<p>Of course test and validate every step, <em>e.g.</em> by comparing to previous steps. </p>
</li>
</ol>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Remember that, <strong><em>for performance</em></strong>, you should <strong><em>avoid using loops in Python</em></strong>. When I implemented the 
cell-based Verlet list construction in Python, it turned out to be terribly slow, mainly because of 5 levels of 
nesting Python loops. The C++ version turned out to be 1200x faster (twelve hundred indeed, no typo!). </p>
</div>
<h4 id="moving-atoms">Moving atoms</h4>
<p>The initalization of a physically consistent system of atoms is a non-trivial task in itself. Because molecular motion 
conserves energy, random positions and velocities at time <script type="math/tex">t=0</script> may pos a lot of trouble for time integration. When 
two atoms happen to be very close they experience very high repulsive force and thus are accelerated vigorously. 
This can easily make the simulation explode. A practical way is to put atoms on a lattice with interatomic distances 
close to the equilibrium distance of the Lennard-Jones potential, <em>e.g.</em> primitive cubic, body-centred cubic (BCC), 
face-centred cubic (FCC), hexagonal closest packing (HCP). then slowly increase random velocities to increase the 
kinetice energy and hence the temperature.</p>
<p>When initializing the system on a lattice, often the performance is rather good because the regular arrangement 
allows for a good data access pattern. However, as (simulation) time proceeds the atoms move and diffusion kicks in. 
Every timestep, some atoms will move in and out of some other atom's Verlet sphere. Gradually, the atoms will move 
further and further from their original positions, but their location in memory does not change, and, consequentially, 
the data access pattern appproaches the random array access we discussed above, leading to considerable performance 
degradation.</p></div></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../js/base.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML" defer></script>
        <script src="../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
